version: 0.0.2
type: plugin
author: chuangsiaihub
name: chuangsiai
created_at: 2025-05-29T11:31:59.339182+08:00
icon: icon.svg
label:
  zh_Hans: 创思大模型安全
  en_US: Chuangsi LLM Safety
description:
  zh_Hans: 创思大模型安全工具是一款面向大语言模型的内容安全防护系统，旨在识别和拦截LLM输入与输出中的潜在安全风险，包括涉政敏感、色情、违法违规行为、负面价值导向、辱骂言论及隐私泄露等内容。针对存在风险的输入，该工具还支持安全可信代答，助力用户实现大模型系统的安全合规。
  en_US: The Chuangsi LLM Safety Toolkit is a comprehensive content security solution designed for large language models (LLMs). It is engineered to detect and mitigate potential safety risks in both model inputs and outputs, including politically sensitive content, explicit material, illegal or non-compliant information, harmful value orientation, abusive language, and privacy violations. For high-risk queries, the toolkit also supports secure and trustworthy response generation, empowering users to build LLM systems that are both safe and compliant.
resource: # 资源配置
  memory: 268435456 # 256MB
  permission:
    tool:
      enabled: false
    model:
      enabled: false
      llm: false
      text_embedding: false
      rerank: false
      tts: false
      speech2text: false
      moderation: false
    node:
      enabled: false
    endpoint:
      enabled: false
    app:
      enabled: false
    storage:
      enabled: false
      size: 1024
plugins: # 插件配置
  tools:
    - provider/chuangsiai.yaml
meta:
  version: 0.0.1
  arch:
    - amd64
    - arm64
  runner:
    language: python
    version: "3.12"
    entrypoint: main
  minimum_dify_version: null
privacy: PRIVACY.md
verified: false
