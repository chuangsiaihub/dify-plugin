## Chuangsi LLM Safety Tools for Dify

**作者：** Chuangsi AI

**版本：** 0.0.4

**类型：** tool

### 概述

创思大模型安全工具是一款面向大语言模型的内容安全防护系统，旨在识别和拦截 LLM 输入与输出中的潜在安全风险，包括涉政敏感、色情、违法违规行为、负面价值导向、辱骂言论及隐私泄露等内容。针对存在风险的输入，该工具还支持安全可信代答，助力用户实现大模型系统的安全合规。

### 主要功能

**安全护栏**：识别并拦截大模型输入与输出中的内容安全风险，包括涉政、色情、违法违规、负面价值观、辱骂仇恨、恶意营销及隐私泄露等问题。
**安全代答**：针对存在潜在风险的输入，提供具备正向引导和内容安全的安全代答能力。
**灵活集成**：可无缝接入 Dify 架构，支持工作流、Agent 等多种对接方式。
**灵活配置**：支持自定义安全关键词、风险问答库与兜底回复，便于快速调整和管控安全策略。

### 基本使用示例

#### 安装及授权

通过 **Marketplace/Github/本地插件**等方式安装插件，安装完毕后点击“去授权”，确保认证成功。

![img1](_assets/img1.png)

#### 在 Chatflow 中调用

可以在 Chatflow 中分别调用插件对输入和输出内容进行检索，同时需要搭配“条件分支”来进行判断，如果检测结果中包含 "allow" 则继续进行工作流，否则返回静态内容，停止工作流。

![img2](_assets/img2.png)

输入侧工具调用示例如下：

<img src="_assets/img3.png" alt="img3" style="zoom:50%;" />

具体参数说明如下：

- 进行输入检查还是输出检查？：PANW AIRS Prompt/Response 标识符，用于区分待检测内容属于输入还是输出
- 应用名称（可选）：该 Chatflow/Agent 的名称，用于日志记录
- 用户名称（可选）：当前应用的用户标识，用于日志记录
- 模型名称（可选）：当前应用所使用的模型名称，用于日志记录
- 指定新的 PANW AIRS Profile Name（可选）：如果想针对该应用使用不同的 Profile，可以通过此参数来调整。默认将会使用全局配置的 Profile Name

输入判断组件配置如下：

<img src="_assets/img4.png" alt="img4" style="zoom:50%;" />

输出侧工具调用示例如下：

<img src="_assets/img5.png" alt="img5" style="zoom:50%;" />

输出判断组件配置如下：

<img src="_assets/img6.png" alt="img6" style="zoom:50%;" />

#### 在 Agent 中调用

<img src="_assets/img7.png" alt="img7" style="zoom:50%;" />

提示词示例：

> 你是一个个人信息查询对话机器人。
>
> 你需要和用户聊天，在聊天前需要先调用 palo_alto_networks_ai_security_api 对用户的输入进行检查，如果检测结果中包含 block，则回复用户“输入已被禁止”，否则请正常回答问题。
>
> 如果用户在询问 Matt 相关的信息，需要查询知识库获取相关的内容。
>
> 在回答问题前，需要先将你想回答的内容调用 palo_alto_networks_ai_security_api 对输出进行检查，如果检测结果中包含 block，则回复用户“输出已被禁止”，否则请正常回答问题。

### 功能演示

<img src="_assets/img8.png" alt="img8" style="zoom:50%;" />

## Changelog

### v0.0.4

- 修复文档链接

### v0.0.3

- 新增恶意代码检测功能，与 API 功能对齐

### v0.0.2

- 新增 Profile Name Override 功能，满足不同应用使用不同的安全策略配置需求（注意：全局依然只能共享使用一个 Key）

### v0.0.1

- 初始版本，实现基本的全局凭据配置，输入检查及输出检查
- 支持下列内容的识别：
  - 提示词注入
  - 恶意 URL
  - 敏感数据检测（支持后台此定义策略）
  - SQL 安全
  - Toxic Content
